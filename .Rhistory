summarize(max_consec_days_missing_Q=max(consec)) %>%
mutate(exclude=max_consec_days_missing_Q>20)
write_csv(consecutive_missing_days,"../../data/format/consecutive_missing_days.csv")
missing_days_plot_breaks <- c(seq(0,100,by=25),consecutive_missing_days %>% pull(max_consec_days_missing_Q)) %>%
unique() %>% sort()
exclude_years <- with(consecutive_missing_days,y[exclude])
p_exclude_years <- ggplot(consecutive_missing_days) +
geom_bar(aes(y,max_consec_days_missing_Q,fill=exclude),stat="identity") +
scale_y_continuous(breaks=c(0,3,25,50,75,100),minor_breaks=missing_days_plot_breaks) +
# geom_abline(data=distinct(consecutive_missing_days %>% select(max_consec_days_missing_Q)),intercept=,slope=0) +
# geom_text
theme(axis.text.x = element_text(angle=90,vjust=0.5))
png(file.path(output_dir_path,"exclude_years_missing_flow.png"),width=400,height=300)
print(p_exclude_years)
dev.off()
q <- q %>% filter(!(y%in%exclude_years)) %>% as_tibble() # & !is.na(Q_cumec)
# 1: difference-in-difference with linear model
# 1a: import function for clustered standard errors
# import the function for robust standard errors from repository to deal with heteroscedasticity
# Description of code is here https://economictheoryblog.com/2016/08/07/robust-standard-errors-in-r-function/ (also saved to evernote)
# and here: https://economictheoryblog.com/2016/08/07/robust-standard-errors/ (also saved to evernote)
url_robust <- "https://raw.githubusercontent.com/IsidoreBeautrelet/economictheoryblog/master/robust_summary.R"
eval(parse(text = getURL(url_robust, ssl.verifypeer = FALSE)),
envir=.GlobalEnv)
# 1b: generate dataframe for lm
q$yday=yday(q$date)
q$y=year(q$date)
q$Q_cumecL=log(q$Q_cumec)
q=subset(q,yday<=(130+dt))
q$y=as.factor(q$y)
# ggplot(q) + geom_point(aes(date,Q_cumec)) + geom_point(data=subset(q,y%in%c("2001","2003","2013")),aes(date,Q_cumec),color="red")
# abc <- subset(q,y%in%c("2001","2013"))
#Ave effect of agreement during low flow period (Feb 18 - May 30)
r=subset(q,yday>(69-dt)&yday<(130+dt)&!is.na(Q_cumecL)) %>% as.data.frame()
r$agPer=!is.na(r$bangladesh_period_shift)
# 1c: linear models and output
#no effect
#effect of agreement during low flow period
r$treat=as.factor(with(r,ifelse(bangladesh_period_shift&!is.na(bangladesh_period_shift),'B',ifelse(!bangladesh_period_shift&!is.na(bangladesh_period_shift),'I','C'))))
r$treat=relevel(r$treat, ref = "C")
r$yday2=r$yday^2
mod1 <- lm(Q_cumecL~post_agreement*agPer,r) # 1c i: effect of agreement in low flow period
mod=lm(Q_cumecL~post_agreement*treat,r) # 1c ii: differentiated effect (by B and I allocation periods) of agreement in low flow period
mod01=lm(Q_cumecL~post_agreement*treat+yday+yday2,r) # 1c iii: differentiated effect (by B and I allocation periods) of agreement in low flow period with day covariate
# mod001=lm(Q_cumecL~post_agreement*treat+y,r) # 1c iv: differentiated effect (by B and I allocation periods) of agreement in low flow period
sink(file.path(output_dir_path,"model_results.txt"),split = TRUE,append = FALSE)
cat("effect of agreement during low flow period (not disaggregated):\n\n")
print(summary(mod1,cluster=c('y')))
cat("differentiated effect of agreement during low flow period:\n\n")
print(summary(mod,cluster=c('y')))
cat("differentiated effect of agreement during low flow period including DOY covariates:\n\n")
print(summary(mod01,cluster=c('y')))
# cat("differentiated effect of agreement during low flow period including year fixed effects:\n\n")
# print(summary(mod001,cluster=c('y')))
sink()
# 23% in B-desh allocated flow
# 3% (unsignificant) effect in I-allocated flow.
# OLD #16% in B-desh allocated flow
# OLD #-3% (unsignificant) effect in I-allocated flow.
# Change dt to show that results are robust to that!
# xtable examples w note:
# https://stackoverflow.com/questions/26790530/xtable-adding-a-title-on-top-and-a-caption-under-the-table
# https://stackoverflow.com/questions/6163823/r-xtable-caption-or-comment
t_mod1 <- broom::tidy(summary(mod1,cluster="y")) %>%
mutate(` `=c("Intercept (log)","Year>1996 ($\\lambda$)","Mar 11--May 10 ($\\gamma$)","Treaty ($\\tau$)"),
`p-value`=ifelse(p.value<0.001,"<0.001",format(round(p.value,3),digits=3))) %>%
select(` `,`effect\\textsuperscript{1}`=estimate,`Std. error`=std.error,`p-value`)
sink(file.path(output_dir_path,"table_diff_in_diff_bulk.txt"),append=FALSE)
print(xtable::xtable(t_mod1,
caption="Bulk regression results for Ganges treaty.",
label="t:diff_in_diff_bulk",align="llrrr"),
sanitize.colnames.function = identity,
sanitize.text.function = identity,
include.rownames = FALSE,
caption.placement="top",
add.to.row = list(list(nrow(t_mod1)),"\\hline \n $^1$ Values indicate relative change with respect to the intercept \n"),
hline.after = c(-1, 0))
sink()
t_mod <- broom::tidy(summary(mod,cluster="y")) %>%
mutate(` `=c("Intercept (log)","Year>1996 ($\\lambda$)","Bangladesh allocation periods ($\\gamma_B$)",
"India allocation period ($\\gamma_I$)","Treaty, Bangladesh ($\\tau_B$)","Treaty, India ($\\tau_I$)"),
`p-value`=ifelse(p.value<0.001,"<0.001",format(round(p.value,3),digits=3))) %>%
select(` `,`effect$^1$`=estimate,`Std. error`=std.error,`p-value`)
sink(file.path(output_dir_path,"table_diff_in_diff_differentiated.txt"),append=FALSE)
print(xtable::xtable(t_mod,
caption="Regression results for treaty, with differentiated allocation periods.",
label="t:diff_in_diff_differentiated",align="llrrr"),
sanitize.colnames.function = identity,
sanitize.text.function = identity,
include.rownames = FALSE,
caption.placement="top",
add.to.row = list(list(nrow(t_mod)),"\\hline \n $^1$ Values indicate relative change with respect to the intercept.\n"),
hline.after = c(-1, 0)
)
sink()
# 2: robustness checks
#robustness check: we assume that agreement period outside of switching low flow is a conservative (if not valid) counterfactual
#Argument is that India was maximizing diversion prior to the agreement, so if anything, the agreement restricted Indian consumption during non-low flow periods.
#Neglecting this effect is conservative in that it would lead to an underestimation of the (positive) effect of the agreement on bdesh period flow and an overestimeation of the (negative) effect during indian period.
# 2a: check control before and after agreement - there IS a change
#Here we check that differences during the control period between pre-and post- agreement disappear when controlling for upstream flow processes -- proxied as annual flow -- DURING JAN-MAY PERIOD (1/1 - 5/30)
s=merge(r,aggregate(q$Q_cumec,by=list(q$y),mean,na.rm=T),by.x='y',by.y='Group.1',all.x=T) #switched from annual mean, to mean for dry season (q$Q_cumec)
s=s[order(s$date),]
s$xL=log(s$x)
control=subset(s,yday>(69-dt)&yday<(130+dt)&is.na(bangladesh_period_shift))
print(summary(lm(Q_cumecL~xL+post_agreement+yday+yday2,control),cluster=c('y')))
summary(lm(Q_cumecL~post_agreement+yday+yday2,control),cluster=c('y'))
sink(file.path(output_dir_path,"control_text.txt"),split=TRUE,append=FALSE)
print(summary(lm(Q_cumecL~post_agreement,control),cluster=c('y')))
sink()
#In other words, the agreement did not effect the streamflow during control period.
# 2b: check mean flow on specific days of the year, using spline
### NOTE - this has been moved to plot_control_period_validation.R
# get spline
q_approx <- do.call(rbind,lapply(split(q,q$y),function(x) x %>% mutate(Q_cusec_approx=approx(yearless_date,Q_cusec,xout=yearless_date)$y))) %>%
as_tibble() %>% group_by()
get_spl <- function(q_approx) { # this function runs a spline and simplifies the results
spl <- with(q_approx %>% filter(!is.na(Q_cusec_approx)),smooth.spline(yday,Q_cusec_approx))
spl_tbl <- spl %>% broom::augment() %>% select(yday=x,Q_cusec_spl=.fitted) %>% distinct() %>%
mutate(post_agreement=q_approx$post_agreement[1])
return(spl_tbl)
}
# the spline is needed to get averae streamflow throughout dryseason (ie, smooth mean value of Q each day of dry season)
q_spl <- do.call(rbind,lapply(split(q_approx,q_approx$post_agreement),get_spl)) %>% as_tibble() %>%
mutate(Q_cusec_spl=round(Q_cusec_spl),
yearless_date=as.Date(paste0("0000-",yday),"%Y-%j"),
treaty_period = factor(post_agreement,levels=c(FALSE,TRUE),labels=c("pre-treaty","post-treaty")))
# q_means <- q_approx %>% select(Q_cumec,Q_cusec_approx,yearless_date) %>% filter(yearless_date %in% as.Date(c("0000-01-31")))
p_dryseason_recession <- q %>% filter(yearless_date <= "0000-3-10") %>%
mutate(treaty_period = factor(post_agreement,levels=c(FALSE,TRUE),labels=c("pre-treaty","post-treaty"))) %>%
ggplot(aes(yearless_date,Q_cusec,color=treaty_period)) +
geom_line(aes(group=y),alpha=0.5) +
geom_smooth() +
geom_point(data=q_spl %>% filter(yearless_date %in% as.Date(c("0000-01-01","0000-02-01","0000-03-01"))),
aes(yearless_date,Q_cusec_spl),size=4,shape=1) +
ggrepel::geom_label_repel(data=q_spl %>% filter(yearless_date %in% as.Date(c("0000-01-01","0000-02-01","0000-03-01"))),
aes(yearless_date,Q_cusec_spl,label=Q_cusec_spl),point.padding=unit(1,"cm"),show.legend = FALSE) +
ylab("Hardinge streamflow, cusec") + xlab("Date") +
theme(legend.title=element_blank(),
legend.position = c(0.8,0.8))
png(file.path(output_dir_path,"dryseason_recession_w_spline.png"),width=800,height=400)
print(p_dryseason_recession)
dev.off()
#
# 2b 1/2?: As another robustness check, we could use AMHG to monitor the flow in the upper ganges and check
#that the flow did not change significantly when controlling for climate.
# 2c: in a more precise model, we control for annual mean flow
s <- plyr::ddply(s,c("y"),transform,Q_cumec_y=mean(Q_cumec,na.rm=TRUE),
Q_cumec_yL=log(mean(Q_cumec,na.rm=TRUE)))
# note:
# xL is s$xL=log(s$x), where x is mean annual flow
# Q_cumec_yL is mean of flow within s (flow subset to dry season)
# 2c i: with annual mean flow as covariate
# ggplot(s %>% filter(date > "1997-01-01")) + geom_line(aes(yearless_date,Q_cumecL,color=y))
mod2=lm(Q_cumecL~post_agreement*treat+xL+yday+yday2,s)
print(summary(mod2,cluster=c('y')))
#R2 jumps to 0.67. Not great, but better than before.
# 2c ii: with annual mean flow interaction term and with years fixed effects
mod3=lm(Q_cumecL~post_agreement*treat*xL+y+yday+yday2,s) #+yday+yday^2 added
print(summary(mod3))
#R2 jumps to 0.75 Decent? We'll use this one for the OLS estimation.
# dim(s[complete.cases(s2[,c('post_agreement','treat','xL','Q_cumec_y','yday2','yday','y')]),])
# 3: generate synthetic streamflow data
#################GLS
#We want to estimate to covariance structure of the dataset.
#We assume that the variance is clustered by year
#and that, within year, the TS process is AR1.
#plug in the varcov matrix into a GLS estiamtion -- it should provide the same results.
acf(residuals(mod3),type='partial') #AR1 should work
# 3a: GLS regression
# 3a i: prepare dataset for GLS regression
library(nlme)
s=s[order(s$date),]
cs1 <- corAR1(0.8, form = ~ yday|y) # the correlation structure for GLS
s$TB=s$treat=='B'
s$TI=s$treat=='I'
s2 <- s[,c('date','Q_cumec','post_agreement','treat','TB','TI','xL','yday','y','yday2','Q_cumec_y')]
s2=s2[complete.cases(s2[,c('date','post_agreement','treat','TB','TI','xL','yday','y','yday2','Q_cumec_y')]),] # removed Q_cumecL
s=s[complete.cases(s[,c('Q_cumecL','post_agreement','TB','TI','xL','yday','y')]),]
# s2 = s
s=s[order(s$date),]
# 3a ii: run GLS regression
gl=gls(Q_cumecL~post_agreement*(TB+TI)+xL+yday+yday2,s,cs1,method='REML') #+yday+yday^2 added
# Works but slightly different estimates, prob due to non normal standard errors. OLS results are unbiased and don't rely on the normality assumption. #We will nonetheless use GLS results to generate the data.
###########Normality of errors
print(shapiro.test(mod3$residuals)) ## Fails!!Mod1 and Mod2 do a bit better
plot(density(mod3$residuals),main='pdf of residuals')
lines(density(rnorm(1000000,0,summary(mod3)$sigma)),col='red')
abline(v=0,col='grey')
legend('topright',legend=c('data','normal'),lty=1,col=1:2)
plot(mod3,which=2)
####################Generating data!
# 3b Generate synthetic data using GLS
# 3b i: function to generate errors given varcov matrix R and SD sigma
getError=function(R,sig=1,N=1000){
#R is varCov kxk
#N is number of replicates
U = t(chol(R)) #cholesky decomposition to generate correlated data
nvars = dim(U)[1]
# set.seed(1)
random.normal = matrix(rnorm(nvars*N,0,sig), nrow=nvars, ncol=N);
X = as.data.frame(U %*% random.normal)
#returns data frame where each column is a replicate.
return(X)
}
gl
# Works but slightly different estimates, prob due to non normal standard errors. OLS results are unbiased and don't rely on the normality assumption. #We will nonetheless use GLS results to generate the data.
###########Normality of errors
print(shapiro.test(mod3$residuals)) ## Fails!!Mod1 and Mod2 do a bit better
plot(density(mod3$residuals),main='pdf of residuals')
library(RCurl)
library(lubridate)
library(tidyverse)
group_name <- "proc_DDNew_final" # name of plot_(group name).R
fig_path <- "../../results/fig"
source(file.path(fig_path,"fig_functions.R"))
setwd("/Users/gopal/Projects/GangesBrahmaputraProject/gbb_github/src/proc")
library(RCurl)
library(lubridate)
library(tidyverse)
# library(tidyverse)
group_name <- "proc_DDNew_final" # name of plot_(group name).R
fig_path <- "../../results/fig"
source(file.path(fig_path,"fig_functions.R"))
outdirectory_fig_path <- get_outdirectory_fig_path(fig_path,"gdrive") #######################
output_dir_path <- file.path(outdirectory_fig_path,group_name)
if (!dir.exists(output_dir_path)) {dir.create(output_dir_path)}
# 0: setup and imports
# 0a: set number of days in control period
dt=20 #number of days before and after the low flow period to include as control.
# 0b: import streamflow data
# q <- readRDS("/Users/gopal/Google Drive/Ganges_shared/Code/Shared/Marc/q_full.rds")
q=readRDS('../../data/format/q_full.rds') %>% as.data.frame()
q$y=year(q$date)
# 0c: check for consecutive missing days and exlude years > 25 consec missing days
consecutive_missing_days <- q %>%
filter(yearless_date > "0000-02-19",yearless_date < "0000-05-31") %>%
group_by(y) %>% mutate(Q_na=is.na(Q_cumec),
consec=sequence(rle(Q_na)$lengths) * Q_na)%>%
summarize(max_consec_days_missing_Q=max(consec)) %>%
mutate(exclude=max_consec_days_missing_Q>20)
write_csv(consecutive_missing_days,"../../data/format/consecutive_missing_days.csv")
missing_days_plot_breaks <- c(seq(0,100,by=25),consecutive_missing_days %>% pull(max_consec_days_missing_Q)) %>%
unique() %>% sort()
exclude_years <- with(consecutive_missing_days,y[exclude])
p_exclude_years <- ggplot(consecutive_missing_days) +
geom_bar(aes(y,max_consec_days_missing_Q,fill=exclude),stat="identity") +
scale_y_continuous(breaks=c(0,3,25,50,75,100),minor_breaks=missing_days_plot_breaks) +
# geom_abline(data=distinct(consecutive_missing_days %>% select(max_consec_days_missing_Q)),intercept=,slope=0) +
# geom_text
theme(axis.text.x = element_text(angle=90,vjust=0.5))
png(file.path(output_dir_path,"exclude_years_missing_flow.png"),width=400,height=300)
print(p_exclude_years)
dev.off()
q <- q %>% filter(!(y%in%exclude_years)) %>% as_tibble() # & !is.na(Q_cumec)
# 1: difference-in-difference with linear model
# 1a: import function for clustered standard errors
# import the function for robust standard errors from repository to deal with heteroscedasticity
# Description of code is here https://economictheoryblog.com/2016/08/07/robust-standard-errors-in-r-function/ (also saved to evernote)
# and here: https://economictheoryblog.com/2016/08/07/robust-standard-errors/ (also saved to evernote)
url_robust <- "https://raw.githubusercontent.com/IsidoreBeautrelet/economictheoryblog/master/robust_summary.R"
eval(parse(text = getURL(url_robust, ssl.verifypeer = FALSE)),
envir=.GlobalEnv)
# 1b: generate dataframe for lm
q$yday=yday(q$date)
q$y=year(q$date)
q$Q_cumecL=log(q$Q_cumec)
q=subset(q,yday<=(130+dt))
q$y=as.factor(q$y)
# ggplot(q) + geom_point(aes(date,Q_cumec)) + geom_point(data=subset(q,y%in%c("2001","2003","2013")),aes(date,Q_cumec),color="red")
# abc <- subset(q,y%in%c("2001","2013"))
#Ave effect of agreement during low flow period (Feb 18 - May 30)
r=subset(q,yday>(69-dt)&yday<(130+dt)&!is.na(Q_cumecL)) %>% as.data.frame()
r$agPer=!is.na(r$bangladesh_period_shift)
# 1c: linear models and output
#no effect
#effect of agreement during low flow period
r$treat=as.factor(with(r,ifelse(bangladesh_period_shift&!is.na(bangladesh_period_shift),'B',ifelse(!bangladesh_period_shift&!is.na(bangladesh_period_shift),'I','C'))))
r$treat=relevel(r$treat, ref = "C")
r$yday2=r$yday^2
mod1 <- lm(Q_cumecL~post_agreement*agPer,r) # 1c i: effect of agreement in low flow period
mod=lm(Q_cumecL~post_agreement*treat,r) # 1c ii: differentiated effect (by B and I allocation periods) of agreement in low flow period
mod01=lm(Q_cumecL~post_agreement*treat+yday+yday2,r) # 1c iii: differentiated effect (by B and I allocation periods) of agreement in low flow period with day covariate
# mod001=lm(Q_cumecL~post_agreement*treat+y,r) # 1c iv: differentiated effect (by B and I allocation periods) of agreement in low flow period
sink(file.path(output_dir_path,"model_results.txt"),split = TRUE,append = FALSE)
cat("effect of agreement during low flow period (not disaggregated):\n\n")
print(summary(mod1,cluster=c('y')))
cat("differentiated effect of agreement during low flow period:\n\n")
print(summary(mod,cluster=c('y')))
cat("differentiated effect of agreement during low flow period including DOY covariates:\n\n")
print(summary(mod01,cluster=c('y')))
# cat("differentiated effect of agreement during low flow period including year fixed effects:\n\n")
# print(summary(mod001,cluster=c('y')))
sink()
# 23% in B-desh allocated flow
# 3% (unsignificant) effect in I-allocated flow.
# OLD #16% in B-desh allocated flow
# OLD #-3% (unsignificant) effect in I-allocated flow.
# Change dt to show that results are robust to that!
# xtable examples w note:
# https://stackoverflow.com/questions/26790530/xtable-adding-a-title-on-top-and-a-caption-under-the-table
# https://stackoverflow.com/questions/6163823/r-xtable-caption-or-comment
t_mod1 <- broom::tidy(summary(mod1,cluster="y")) %>%
mutate(` `=c("Intercept (log)","Year>1996 ($\\lambda$)","Mar 11--May 10 ($\\gamma$)","Treaty ($\\tau$)"),
`p-value`=ifelse(p.value<0.001,"<0.001",format(round(p.value,3),digits=3))) %>%
select(` `,`effect\\textsuperscript{1}`=estimate,`Std. error`=std.error,`p-value`)
sink(file.path(output_dir_path,"table_diff_in_diff_bulk.txt"),append=FALSE)
print(xtable::xtable(t_mod1,
caption="Bulk regression results for Ganges treaty.",
label="t:diff_in_diff_bulk",align="llrrr"),
sanitize.colnames.function = identity,
sanitize.text.function = identity,
include.rownames = FALSE,
caption.placement="top",
add.to.row = list(list(nrow(t_mod1)),"\\hline \n $^1$ Values indicate relative change with respect to the intercept \n"),
hline.after = c(-1, 0))
sink()
t_mod <- broom::tidy(summary(mod,cluster="y")) %>%
mutate(` `=c("Intercept (log)","Year>1996 ($\\lambda$)","Bangladesh allocation periods ($\\gamma_B$)",
"India allocation period ($\\gamma_I$)","Treaty, Bangladesh ($\\tau_B$)","Treaty, India ($\\tau_I$)"),
`p-value`=ifelse(p.value<0.001,"<0.001",format(round(p.value,3),digits=3))) %>%
select(` `,`effect$^1$`=estimate,`Std. error`=std.error,`p-value`)
sink(file.path(output_dir_path,"table_diff_in_diff_differentiated.txt"),append=FALSE)
print(xtable::xtable(t_mod,
caption="Regression results for treaty, with differentiated allocation periods.",
label="t:diff_in_diff_differentiated",align="llrrr"),
sanitize.colnames.function = identity,
sanitize.text.function = identity,
include.rownames = FALSE,
caption.placement="top",
add.to.row = list(list(nrow(t_mod)),"\\hline \n $^1$ Values indicate relative change with respect to the intercept.\n"),
hline.after = c(-1, 0)
)
sink()
# 2: robustness checks
#robustness check: we assume that agreement period outside of switching low flow is a conservative (if not valid) counterfactual
#Argument is that India was maximizing diversion prior to the agreement, so if anything, the agreement restricted Indian consumption during non-low flow periods.
#Neglecting this effect is conservative in that it would lead to an underestimation of the (positive) effect of the agreement on bdesh period flow and an overestimeation of the (negative) effect during indian period.
# 2a: check control before and after agreement - there IS a change
#Here we check that differences during the control period between pre-and post- agreement disappear when controlling for upstream flow processes -- proxied as annual flow -- DURING JAN-MAY PERIOD (1/1 - 5/30)
s=merge(r,aggregate(q$Q_cumec,by=list(q$y),mean,na.rm=T),by.x='y',by.y='Group.1',all.x=T) #switched from annual mean, to mean for dry season (q$Q_cumec)
s=s[order(s$date),]
s$xL=log(s$x)
control=subset(s,yday>(69-dt)&yday<(130+dt)&is.na(bangladesh_period_shift))
print(summary(lm(Q_cumecL~xL+post_agreement+yday+yday2,control),cluster=c('y')))
summary(lm(Q_cumecL~post_agreement+yday+yday2,control),cluster=c('y'))
sink(file.path(output_dir_path,"control_text.txt"),split=TRUE,append=FALSE)
print(summary(lm(Q_cumecL~post_agreement,control),cluster=c('y')))
sink()
#In other words, the agreement did not effect the streamflow during control period.
# 2b: check mean flow on specific days of the year, using spline
### NOTE - this has been moved to plot_control_period_validation.R
# get spline
q_approx <- do.call(rbind,lapply(split(q,q$y),function(x) x %>% mutate(Q_cusec_approx=approx(yearless_date,Q_cusec,xout=yearless_date)$y))) %>%
as_tibble() %>% group_by()
get_spl <- function(q_approx) { # this function runs a spline and simplifies the results
spl <- with(q_approx %>% filter(!is.na(Q_cusec_approx)),smooth.spline(yday,Q_cusec_approx))
spl_tbl <- spl %>% broom::augment() %>% select(yday=x,Q_cusec_spl=.fitted) %>% distinct() %>%
mutate(post_agreement=q_approx$post_agreement[1])
return(spl_tbl)
}
# the spline is needed to get averae streamflow throughout dryseason (ie, smooth mean value of Q each day of dry season)
q_spl <- do.call(rbind,lapply(split(q_approx,q_approx$post_agreement),get_spl)) %>% as_tibble() %>%
mutate(Q_cusec_spl=round(Q_cusec_spl),
yearless_date=as.Date(paste0("0000-",yday),"%Y-%j"),
treaty_period = factor(post_agreement,levels=c(FALSE,TRUE),labels=c("pre-treaty","post-treaty")))
# q_means <- q_approx %>% select(Q_cumec,Q_cusec_approx,yearless_date) %>% filter(yearless_date %in% as.Date(c("0000-01-31")))
p_dryseason_recession <- q %>% filter(yearless_date <= "0000-3-10") %>%
mutate(treaty_period = factor(post_agreement,levels=c(FALSE,TRUE),labels=c("pre-treaty","post-treaty"))) %>%
ggplot(aes(yearless_date,Q_cusec,color=treaty_period)) +
geom_line(aes(group=y),alpha=0.5) +
geom_smooth() +
geom_point(data=q_spl %>% filter(yearless_date %in% as.Date(c("0000-01-01","0000-02-01","0000-03-01"))),
aes(yearless_date,Q_cusec_spl),size=4,shape=1) +
ggrepel::geom_label_repel(data=q_spl %>% filter(yearless_date %in% as.Date(c("0000-01-01","0000-02-01","0000-03-01"))),
aes(yearless_date,Q_cusec_spl,label=Q_cusec_spl),point.padding=unit(1,"cm"),show.legend = FALSE) +
ylab("Hardinge streamflow, cusec") + xlab("Date") +
theme(legend.title=element_blank(),
legend.position = c(0.8,0.8))
png(file.path(output_dir_path,"dryseason_recession_w_spline.png"),width=800,height=400)
print(p_dryseason_recession)
dev.off()
#
# 2b 1/2?: As another robustness check, we could use AMHG to monitor the flow in the upper ganges and check
#that the flow did not change significantly when controlling for climate.
# 2c: in a more precise model, we control for annual mean flow
s <- plyr::ddply(s,c("y"),transform,Q_cumec_y=mean(Q_cumec,na.rm=TRUE),
Q_cumec_yL=log(mean(Q_cumec,na.rm=TRUE)))
# note:
# xL is s$xL=log(s$x), where x is mean annual flow
# Q_cumec_yL is mean of flow within s (flow subset to dry season)
# 2c i: with annual mean flow as covariate
# ggplot(s %>% filter(date > "1997-01-01")) + geom_line(aes(yearless_date,Q_cumecL,color=y))
mod2=lm(Q_cumecL~post_agreement*treat+xL+yday+yday2,s)
print(summary(mod2,cluster=c('y')))
#R2 jumps to 0.67. Not great, but better than before.
# 2c ii: with annual mean flow interaction term and with years fixed effects
mod3=lm(Q_cumecL~post_agreement*treat*xL+y+yday+yday2,s) #+yday+yday^2 added
print(summary(mod3))
#R2 jumps to 0.75 Decent? We'll use this one for the OLS estimation.
# dim(s[complete.cases(s2[,c('post_agreement','treat','xL','Q_cumec_y','yday2','yday','y')]),])
# 3: generate synthetic streamflow data
#################GLS
#We want to estimate to covariance structure of the dataset.
#We assume that the variance is clustered by year
#and that, within year, the TS process is AR1.
#plug in the varcov matrix into a GLS estiamtion -- it should provide the same results.
acf(residuals(mod3),type='partial') #AR1 should work
# 3a: GLS regression
# 3a i: prepare dataset for GLS regression
library(nlme)
s=s[order(s$date),]
cs1 <- corAR1(0.8, form = ~ yday|y) # the correlation structure for GLS
s$TB=s$treat=='B'
s$TI=s$treat=='I'
s2 <- s[,c('date','Q_cumec','post_agreement','treat','TB','TI','xL','yday','y','yday2','Q_cumec_y')]
s2=s2[complete.cases(s2[,c('date','post_agreement','treat','TB','TI','xL','yday','y','yday2','Q_cumec_y')]),] # removed Q_cumecL
s=s[complete.cases(s[,c('Q_cumecL','post_agreement','TB','TI','xL','yday','y')]),]
# s2 = s
s=s[order(s$date),]
# 3a ii: run GLS regression
gl=gls(Q_cumecL~post_agreement*(TB+TI)+xL+yday+yday2,s,cs1,method='REML') #+yday+yday^2 added
# Works but slightly different estimates, prob due to non normal standard errors. OLS results are unbiased and don't rely on the normality assumption. #We will nonetheless use GLS results to generate the data.
###########Normality of errors
print(shapiro.test(mod3$residuals)) ## Fails!!Mod1 and Mod2 do a bit better
plot(density(mod3$residuals),main='pdf of residuals')
lines(density(rnorm(1000000,0,summary(mod3)$sigma)),col='red')
abline(v=0,col='grey')
legend('topright',legend=c('data','normal'),lty=1,col=1:2)
plot(mod3,which=2)
####################Generating data!
# 3b Generate synthetic data using GLS
# 3b i: function to generate errors given varcov matrix R and SD sigma
getError=function(R,sig=1,N=1000){
#R is varCov kxk
#N is number of replicates
U = t(chol(R)) #cholesky decomposition to generate correlated data
nvars = dim(U)[1]
# set.seed(1)
random.normal = matrix(rnorm(nvars*N,0,sig), nrow=nvars, ncol=N);
X = as.data.frame(U %*% random.normal)
#returns data frame where each column is a replicate.
return(X)
}
# 3b ii: Generate random errors from GLS VarCov matrix
#Errors by year (the intra-annual errors of dryseason)
ers=NULL
set.seed(1)
for(i in 1:(length(unique(s$y)))){
if(dim(getVarCov(gl,individual=i))[1]!=nrow(subset(s,y==unique(s$y)[i]))) print('FAIL') # make sure dimensions of varcov match num observations for that year
ers=rbind(ers,getError(getVarCov(gl,individual=i),summary(gl)$sigma)) # get error terms for that year
}
# 3b iii: generate synthetic counterfactual data from GLS
#Predict
predGLS=exp(gl$fitted+ers)
# s$Mpred=rowMeans(pred)
predGLS=cbind(subset(s,select=c(date,Q_cumec)),predGLS)
# saveRDS(predGLS,'./predGLS.rds')
#noagreement
predGLSNO=exp(gl$fitted+ers-(t(gl$coefficients['post_agreementTRUE:TBTRUE']%*%(s$TB*s$post_agreement))+t(gl$coefficients['post_agreementTRUE:TITRUE']%*%(s$TI*s$post_agreement))))
# s$MpredNO=rowMeans(predGLSNO)
predGLSNO=cbind(subset(s,select=c(date,Q_cumec)),predGLSNO)
# saveRDS(predGLSNO,'./predGLSNO.rds')
# 3c: Simulations using estimates and SE from OLS model mod3, but varcov from GLS
# 3c i: generate errors
#Errors by year
ers=NULL
# for(i in 1:(length(unique(s$y)))){
#   if(dim(getVarCov(gl,individual=i))[1]!=nrow(subset(s,y==unique(s$y)[i]))) print('FAIL')
#   # R <- dim(getVarCov(gl,individual=i))
#   print(dim(getVarCov(gl,individual=i)))
#   # print(getVarCov(gl,individual=i)[1:10,1:10])
# }
set.seed(2)
for(i in 1:(length(unique(s2$y)))){
# if(dim(getVarCov(gl,individual=i))[1]!=nrow(subset(s2,y==unique(s$y)[i]))) print('FAIL')
ers=rbind(ers,getError(getVarCov(gl,individual=1),summary(mod3)$sigma))
# i <- i + 1
}
# 3c ii: generate predOLS_pre using s2 with the agreement (mod3)
# 3c iii: combine with errors & calculate xL_pre
#Predict
predOLS_pre <- s2 %>% select(date,Q_cumec) %>%
bind_cols(exp(predict(mod3,s2)+ers))
s2_predOLS_pre <- s2 %>% select(post_agreement,treat,y,yday,yday2,TB,TI,xL) %>%
bind_cols(predOLS_pre) %>% as.tibble() %>%
gather(sim,Q_cumec_predOLS_pre,V1:V1000) %>%
mutate(sim=factor(sim,levels=paste0("V",as.character(1:1000)))) %>%
group_by(sim,y) %>%
mutate(log_Q_cumec_predOLS_pre=log(Q_cumec_predOLS_pre),
xL_synth=log(mean(Q_cumec_predOLS_pre))) %>% group_by()
# 3c iv: calculate predOLSNO by removing effect of agreement (using xL), using model: mod3=lm(Q_cumecL~post_agreement*treat*xL+y+yday+yday2,s)
s2_predOLSNO <- s2_predOLS_pre  %>%
mutate(log_Q_cumec_predOLSNO = log_Q_cumec_predOLS_pre - (
(mod3$coefficients['post_agreementTRUE:treatB']*   TB*post_agreement) +
(mod3$coefficients['post_agreementTRUE:treatI']*   TI*post_agreement) +
(mod3$coefficients['post_agreementTRUE:treatB:xL']*TB*post_agreement*xL) +
(mod3$coefficients['post_agreementTRUE:treatI:xL']*TI*post_agreement*xL)),
Q_cumec_predOLSNO=exp(log_Q_cumec_predOLSNO))
# 3a ii: run GLS regression
gl=gls(Q_cumecL~post_agreement*(TB+TI)+xL+yday+yday2,s,cs1,method='REML') #+yday+yday^2 added
# Works but slightly different estimates, prob due to non normal standard errors. OLS results are unbiased and don't rely on the normality assumption. #We will nonetheless use GLS results to generate the data.
###########Normality of errors
print(shapiro.test(mod3$residuals)) ## Fails!!Mod1 and Mod2 do a bit better
plot(density(mod3$residuals),main='pdf of residuals')
lines(density(rnorm(1000000,0,summary(mod3)$sigma)),col='red')
abline(v=0,col='grey')
legend('topright',legend=c('data','normal'),lty=1,col=1:2)
plot(mod3,which=2)
# 2c ii: with annual mean flow interaction term and with years fixed effects
mod3=lm(Q_cumecL~post_agreement*treat*xL+y+yday+yday2,s) #+yday+yday^2 added
print(summary(mod3))
